<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 3.9.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">
  <meta name="google-site-verification" content="9qoov3_TfJJpNB8lTPmTyQIFty7THrrcKf5gynDis6c">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic|Roboto Mono:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '7.5.0',
    exturl: false,
    sidebar: {"position":"left","display":"always","padding":18,"offset":12,"onmobile":false},
    copycode: {"enable":true,"show_result":true,"style":"mac"},
    back2top: {"enable":true,"sidebar":true,"scrollpercent":true},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: '',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    translation: {
      copy_button: '复制',
      copy_success: '复制成功',
      copy_failure: '复制失败'
    },
    sidebarPadding: 40
  };
</script>

  <meta name="description" content="在这一章和上一章中间还有一章是讲 MATLAB 编程的，跳过，不做笔记了，这个没什么好笔记的。 这一章开始讲逻辑回归分析 Logistic Regression。 6.1 Classification and Repressentation6.1.1 Classification从这一节开始讨论分类问题，并介绍一种新的算法——逻辑回归，这也是目前最受欢迎和广泛使用的学习算法之一。 刚开始是二分类(">
<meta name="keywords" content="Andrew Ng Machine Learning,MOOC">
<meta property="og:type" content="article">
<meta property="og:title" content="Andrew Ng Machine Learning - 6 Logistic Regression">
<meta property="og:url" content="http://www.liyaolife.com/ng_ml/ng_ml6/index.html">
<meta property="og:site_name" content="Yao Blog">
<meta property="og:description" content="在这一章和上一章中间还有一章是讲 MATLAB 编程的，跳过，不做笔记了，这个没什么好笔记的。 这一章开始讲逻辑回归分析 Logistic Regression。 6.1 Classification and Repressentation6.1.1 Classification从这一节开始讨论分类问题，并介绍一种新的算法——逻辑回归，这也是目前最受欢迎和广泛使用的学习算法之一。 刚开始是二分类(">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https://i.loli.net/2020/03/04/4PQK9wnZSRfW85b.png">
<meta property="og:image" content="https://i.loli.net/2020/03/04/s6FvqnYz7gkpjE8.png">
<meta property="og:image" content="https://i.loli.net/2020/03/04/Prg7bLjCJmElAyR.png">
<meta property="og:image" content="https://i.loli.net/2020/03/04/lBKFPu8qoE2WSkj.png">
<meta property="og:image" content="https://i.loli.net/2020/03/04/gdarWysE8BOS6mx.png">
<meta property="og:image" content="https://i.loli.net/2020/03/04/rBh4VZHXqWUDiLl.png">
<meta property="og:image" content="https://i.loli.net/2020/03/04/scDfvtC8FA9IYnl.png">
<meta property="og:image" content="https://i.loli.net/2020/03/10/zZCgrEK9UmbTkpj.png">
<meta property="og:image" content="https://i.loli.net/2020/03/10/Y2oRwWNJMebZA3t.png">
<meta property="og:image" content="https://i.loli.net/2020/03/10/PgA2F8lrSevT7IX.png">
<meta property="og:image" content="https://i.loli.net/2020/03/10/QGISbJOPox94hlA.png">
<meta property="og:image" content="https://i.loli.net/2020/03/10/dFayDtIo5uhw8SH.png">
<meta property="og:image" content="https://i.loli.net/2020/03/10/Yad7munV34MQCIl.png">
<meta property="og:image" content="https://i.loli.net/2020/03/10/5EWTpLO1dvbsmfZ.png">
<meta property="og:image" content="https://i.loli.net/2020/03/10/FHfw9iVpeSQGLNn.png">
<meta property="og:updated_time" content="2020-03-10T13:32:12.396Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Andrew Ng Machine Learning - 6 Logistic Regression">
<meta name="twitter:description" content="在这一章和上一章中间还有一章是讲 MATLAB 编程的，跳过，不做笔记了，这个没什么好笔记的。 这一章开始讲逻辑回归分析 Logistic Regression。 6.1 Classification and Repressentation6.1.1 Classification从这一节开始讨论分类问题，并介绍一种新的算法——逻辑回归，这也是目前最受欢迎和广泛使用的学习算法之一。 刚开始是二分类(">
<meta name="twitter:image" content="https://i.loli.net/2020/03/04/4PQK9wnZSRfW85b.png">

<link rel="canonical" href="http://www.liyaolife.com/ng_ml/ng_ml6/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true,
    isPage: false,
    isArchive: false
  };
</script>

  <title>Andrew Ng Machine Learning - 6 Logistic Regression | Yao Blog</title>
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-116714676-1"></script>
    <script>
      var host = window.location.hostname;
      if (host !== "localhost" || !true) {
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'UA-116714676-1');
      }
    </script>


  <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?8f8d97cfe412b0747bae34fbfba6e0f6";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Yao Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">图书馆里的清洁工 少林寺里的扫地僧</p>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类</a>

  </li>
        <li class="menu-item menu-item-读书">

    <a href="https://liyaolife.com/kindle/" rel="noopener" target="_blank"><i class="fa fa-fw fa-book"></i>读书</a>

  </li>
        <li class="menu-item menu-item-友邻">

    <a href="/friend/" rel="section"><i class="fa fa-fw fa-link"></i>友邻</a>

  </li>
  </ul>

</nav>
</div>
    </header>

    

  <a href="https://github.com/GeneralLi95" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://www.liyaolife.com/ng_ml/ng_ml6/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Li Yao">
      <meta itemprop="description" content="图书馆里的扫地僧 少林寺里的清洁工">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Yao Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Andrew Ng Machine Learning - 6 Logistic Regression
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-03-03 23:58:30" itemprop="dateCreated datePublished" datetime="2020-03-03T23:58:30+08:00">2020-03-03</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-03-10 21:32:12" itemprop="dateModified" datetime="2020-03-10T21:32:12+08:00">2020-03-10</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning/" itemprop="url" rel="index">
                    <span itemprop="name">Machine Learning</span>
                  </a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning/Stanford-Andrew-Ng-Machine-Learning-Course/" itemprop="url" rel="index">
                    <span itemprop="name">Stanford Andrew Ng Machine Learning Course</span>
                  </a>
                </span>
            </span>

          
            <span id="/ng_ml/ng_ml6/" class="post-meta-item leancloud_visitors" data-flag-title="Andrew Ng Machine Learning - 6 Logistic Regression" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/ng_ml/ng_ml6/#comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/ng_ml/ng_ml6/" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="fa fa-file-word-o"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>6.1k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="fa fa-clock-o"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>10 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>在这一章和上一章中间还有一章是讲 MATLAB 编程的，跳过，不做笔记了，这个没什么好笔记的。</p>
<p>这一章开始讲逻辑回归分析 Logistic Regression。</p>
<h2 id="6-1-Classification-and-Repressentation"><a href="#6-1-Classification-and-Repressentation" class="headerlink" title="6.1 Classification and Repressentation"></a>6.1 Classification and Repressentation</h2><h3 id="6-1-1-Classification"><a href="#6-1-1-Classification" class="headerlink" title="6.1.1 Classification"></a>6.1.1 Classification</h3><p>从这一节开始讨论分类问题，并介绍一种新的算法——逻辑回归，这也是目前最受欢迎和广泛使用的学习算法之一。</p>
<p>刚开始是二分类(binary classification problem)问题，也即一个 0-1 分类问题，绝了一个现实生活中的例子，肿瘤的良性或恶性，垃圾邮件的是与否。然后首先讲了为什么线性回归不能应用在分类问题。</p>
<p>对于二分类问题，结果是0或者1，而线性回归得出的方程是一条斜线，那么我们必须在斜线上设置一个 threshold，高于它的部分设置为1，低于它的部分设置为0，而这个阈值会受到极端值的非常大影响，导致数据会严重失真，分类器无法准确分类。</p>
<p><strong>quiz</strong></p>
<p>Which of the following statements is true?</p>
<ul>
<li>If linear regression doesn’t work on a classification task as in the previous example shown in the video, applying feature scaling may help.</li>
<li>If the training set satisfies $0 \le y^{(i)} \le 1$ for every training example<br>$(x^{(i)}, y^{(i)})$, then linear regression’s prediction will also satisfy $0 \le h_\theta(x) \le 1$ for all values of x.</li>
<li>If there is a feature $x$ that perfectly predicts $y$, i.e. if $y = 1$ when $x \ge c$ and $y=0$ whenever $x&lt;c$ (for some constant $c$), then linear regression will obtain zero classification error.</li>
<li><strong>None of the above statements are true.</strong><br>答案是第四项，以上都不对。</li>
</ul>
<p>总结，逻辑回归算法就是对于 y 是固定值场合。</p>
<h3 id="6-1-2-Hypothesis-Representation"><a href="#6-1-2-Hypothesis-Representation" class="headerlink" title="6.1.2 Hypothesis Representation"></a>6.1.2 Hypothesis Representation</h3><p>那么用线性回归无法表示分类问题，分类问题的数学表示，开始引入 Sigmoid Function 或 Logistic Function</p>
<p>$$h_\theta(x)=g(\theta^T x)$$<br>$$z = \theta^Tx$$<br>$$g(z)=\frac{1}{1+e^{-z}}$$</p>
<p>$g(z)$的函数图像为<br><img src="https://i.loli.net/2020/03/04/4PQK9wnZSRfW85b.png" alt><br>完成了从实数域到 0-1 的映射，同时这个函数给出了结果为1的概率，比如 $h_\theta(x)=0.7$ 就意味着分类结果有 70% 的可能性是 1，而结果是 0 的概率即为 30%。</p>
<h3 id="6-2-1-Decision-Boundary"><a href="#6-2-1-Decision-Boundary" class="headerlink" title="6.2.1 Decision Boundary"></a>6.2.1 Decision Boundary</h3><blockquote>
<p>recap 记录</p>
</blockquote>
<p>决策边界<br>$h_\theta(x)$ 的值虽然被映射到 0-1 之间，但是它依然不是 0 或者 1，而是0-1之间的连续数，我们需要指定值，当其大于0.5时，认为分类为1，当其小于0.5时，认为分类值为0。<strong>对于$h_\theta(x) = g(\theta^Tx)$其大于或小于0.5，就是 $\theta^Tx$ 大于或小于0。</strong><br><img src="https://i.loli.net/2020/03/04/s6FvqnYz7gkpjE8.png" alt></p>
<p>有一些决策边界是非线性边界，比如圆。对于多项式决策方程，其对应的决策边界可能是各种奇奇怪怪的形状。<br><img src="https://i.loli.net/2020/03/04/Prg7bLjCJmElAyR.png" alt></p>
<h2 id="6-2-Logistic-Regression-Model"><a href="#6-2-Logistic-Regression-Model" class="headerlink" title="6.2 Logistic Regression Model"></a>6.2 Logistic Regression Model</h2><h3 id="6-2-1-Cost-Function"><a href="#6-2-1-Cost-Function" class="headerlink" title="6.2.1 Cost Function"></a>6.2.1 Cost Function</h3><blockquote>
<p>convex function 凸函数<br>non-convex function 非凸函数<br>nonlinear 非线性<br>approach to 趋近于</p>
</blockquote>
<p>下面开始介绍Logistic Regression 的损失函数</p>
<p>训练集: ${ (x^{(1)},y^{(1)}),(x^{(2)},y^{(2)}),…,(x^{(m)},y^{(m)}) }$<br>m个样本<br>$$x \in \left[ \begin{array}{ccc}x_0 \\ x_1 \\ … \\ x_n \end{array}\right] x_0=1, y \in { 0,1 }$$</p>
<p>$$h_\theta(x) = \frac{1}{1+e^{-\theta^Tx}}$$<br>该如何选择参数向量 $\theta$<br>复习一下线性回归的损失函数:<br>$$J(\theta) =  \frac{1}{2m}\sum^m_{i=1}(h_\theta(x^{(i)})-y^{(i)})^2$$<br>如果我们将这个损失函数直接运用在 Logistic Regression 上，则这个损失函数将是一个非凸函数，而梯度下降法要求损失函数一定要是一个凸函数。<br><img src="https://i.loli.net/2020/03/04/lBKFPu8qoE2WSkj.png" alt><br>所以我们需要找到一个损失函数，使其为一个凸函数。</p>
<p>注意这不是分段函数!n<br>$$<br>Cost(h_\theta(x),y) = \left{<br>\begin{aligned}<br>-log(h_\theta(x)) \quad if \quad y = 1 \<br>-log(1-h_\theta(x)) \quad if \quad y = 0 \<br>\end{aligned}<br>\right.<br>$$</p>
<p><img src="https://i.loli.net/2020/03/04/gdarWysE8BOS6mx.png" alt><br>当 y = 1 且 $h_\theta(x)=1$时，这时候损失为0。<br>而当 $h_\theta(x) \rightarrow 0$ 的时候，$x \downarrow$,$h_\theta(x)\downarrow$，$Cost \uparrow$ 损失函数趋近于无穷大。<br>而当 y = 0 且 $h_\theta(x)=0$的时候，损失值也是0。<br>注意 $log(x)$ 和 $log(1-x)$是关于将$log(x)$ 先对称再平移。<br>当$h_\theta(x) \rightarrow 0$，这时候随着$h_\theta(x) \rightarrow 1$，$x\uparrow$，$h_\theta(x)\uparrow$，$Cost\uparrow$。</p>
<p><img src="https://i.loli.net/2020/03/04/rBh4VZHXqWUDiLl.png" alt="Cost function when y = 0"></p>
<p><strong>quiz</strong></p>
<p><img src="https://i.loli.net/2020/03/04/scDfvtC8FA9IYnl.png" alt><br>答案是1，2，4.损失函数值是一直大于等于零的。只有当其$y$为 1 或者 0 的时候不是。</p>
<h3 id="6-2-2-Simplified-Cost-Function-and-Gradient-Descent"><a href="#6-2-2-Simplified-Cost-Function-and-Gradient-Descent" class="headerlink" title="6.2.2 Simplified Cost Function and Gradient Descent"></a>6.2.2 Simplified Cost Function and Gradient Descent</h3><p>这节开始尝试简化损失函数的写法。<br>之前损失函数写法：<br>$$J(\theta) =  \frac{1}{m}\sum^m_{i=1}Cost(h_\theta(x^{(i)}),y^{(i)})$$<br>$$<br>Cost(h_\theta(x),y) = \left{<br>\begin{aligned}<br>-log(h_\theta(x)) \quad if \quad y = 1 \<br>-log(1-h_\theta(x)) \quad if \quad y = 0 \<br>\end{aligned}<br>\right.<br>$$<br>Note: y = 0 or 1 always</p>
<p>是否存在一种方法，将损失函数写成一行。答案是存在的，因为 y 始终等于 0 或者 1，所以可以构造多<br>$$<br>Cost(h_\theta(x),y) =<br>-y logh_\theta(x)<br>-(1-y)log(1-h_\theta(x))<br>$$</p>
<p>所以<br>$$<br>J(\theta) =  -\frac{1}{m}\sum^m_{i=1}[y^{(i)} logh_\theta(x^{(i)})+<br>(1-y^{(i)})log(1-h_\theta(x^{(i)}))]<br>$$<br>那么接下来按照梯度下降法，该求偏导数了，<code>这个非常重要的偏导数求导过程ng居然给省略了...</code>，可能是如果有这个推导这个课程难度会增加一个 level 吧。</p>
<blockquote>
<p>identical 相同的</p>
</blockquote>
<p><strong>我还是决定来推导一下这个公式</strong><br>首先复习两个公式：<br>$$\frac{d}{d_x}log_a f(x) = \frac{1}{a \ln f(x)}f’(x)$$<br>$$(e^{ax})’=ae^{ax}$$<br>故<br>$$\frac{\partial}{\partial \theta}J(\theta)=<br>-\frac{1}{m}\sum^m_{i=1}<br>[y^{(i)} \frac{\partial}{\partial \theta}logh_\theta(x^{(i)})+<br>(1-y^{(i)})\frac{\partial}{\partial \theta}log(1-h_\theta(x^{(i)}))]$$</p>
<p>先计算<br>$$<br>\begin{aligned}<br>\frac{\partial}{\partial \theta}logh_\theta(x^{(i)}) &amp;= \frac{\partial}{\partial \theta}log({\frac{1}{1+e^{-\theta^Tx}}}) \<br>&amp;= \frac{\partial}{\partial \theta}[log(1)-log(1+e^{-\theta^Tx})] \<br>&amp;= -\frac{\partial}{\partial \theta}log(1+e^{-\theta^Tx}) \<br>&amp;=  -\frac{1}{1+e^{-\theta^Tx}} \frac{\partial}{\partial \theta}(1+e^{-\theta^Tx}) \<br>&amp;= \frac{x}{1+e^{-\theta^Tx}}e^{-\theta^Tx}  \<br>&amp;= （1-\frac{1}{1+e^{-\theta^tx}})x_j  \<br>&amp;=  (1-h_\theta(x^{(i)}))x^{(i)}_j<br>\end{aligned}<br>$$</p>
<p>再计算</p>
<p>$$ \begin{aligned}<br>\frac{\partial}{\partial \theta}log(1-h_\theta(x^{(i)})) &amp;= \frac{\partial}{\partial \theta}log({1- \frac{1}{1+e^{-\theta^Tx}}}) \<br>&amp;= \frac{\partial}{\partial \theta}log({\frac{e^{-\theta^Tx}}{1+e^{-\theta^Tx}}})\<br>&amp;= \frac{\partial}{\partial \theta}[log(e^{-\theta^Tx})-log(1+e^{-\theta^Tx})] \<br>&amp;= \frac{\partial}{\partial \theta}log(e^{-\theta^Tx})-\frac{\partial}{\partial \theta}log(1+e^{-\theta^Tx}) \<br>&amp;= \frac{\partial}{\partial \theta}({-\theta^Tx})   -\frac{1}{1+e^{-\theta^Tx}} \frac{\partial}{\partial \theta}(1+e^{-\theta^Tx}) \<br>&amp;= -x<br>+\frac{x}{1+e^{-\theta^Tx}}e^{-\theta^Tx} \<br>&amp;= -\frac{1}{1+e^{-\theta^tx}}x_j \<br>&amp;= -h_\theta(x^{(i)})x^{(i)}_j<br>\end{aligned}$$</p>
<p>代入源式子：</p>
<p>$$<br>\begin{aligned}<br>\frac{\partial}{\partial \theta}J(\theta) &amp;=<br>-\frac{1}{m}\sum^m_{i=1}<br>[y^{(i)} \frac{\partial}{\partial \theta}logh_\theta(x^{(i)})+<br>(1-y^{(i)})\frac{\partial}{\partial \theta}log(1-h_\theta(x^{(i)}))] \<br>&amp;= -\frac{1}{m}\sum^m_{i=1}[[y^{(i)} (1-h_\theta(x^{(i)}))x^{(i)}<em>j - (1-y^{(i)})h</em>\theta(x^{(i)})x^{(i)}<em>j ] \<br>&amp;= -\frac{1}{m}\sum^m</em>{i=1}[y^{(i)}x^{(i)}<em>j - h</em>\theta(x^{(i)})x^{(i)}<em>j] \<br>&amp;= \frac{1}{m}\sum^m</em>{i=1}(h_\theta(x^{(i)}) - y^{(i)})x^{(i)}_j<br>\end{aligned}<br>$$</p>
<p><strong>推导结束！</strong><br>即可知，梯度下降法的更新方程是：<br>$$\theta_j = \theta_j -  \frac{\alpha}{m}\sum^m_{i=1}(h_\theta(x^{(i)}) - y^{(i)})x^{(i)}_j$$<br>会发现这个迭代公式和线性回归的迭代公式竟然是一致的！<br>向量化实现：<br>$$\theta = \theta - \frac{\alpha}{m}X^T(g(X\theta)- \vec{y})$$</p>
<p><img src="https://i.loli.net/2020/03/10/zZCgrEK9UmbTkpj.png" alt></p>
<h3 id="6-2-3-Advanced-Optimization"><a href="#6-2-3-Advanced-Optimization" class="headerlink" title="6.2.3 Advanced Optimization"></a>6.2.3 Advanced Optimization</h3><p>这一节探讨一些优化的方法。在计算完损失函数与偏导数之后，可以使用梯度下降法，也有其他方法。</p>
<ul>
<li>Gradient 梯度下降法</li>
<li>Conjugate gradient 共轭梯度法</li>
<li>BFGs 变尺度法</li>
<li>L-BFGs 限制变尺度法</li>
</ul>
<p>后三种方法在本课程中不讲，他们的优点是，不需要手动选择学习率 $\alpha$，并且一般都会比梯度下降法快一些，但是他们的劣势就是更加的复杂。Ng提到有时候不需要知道这些算法的细节，只需要会使用即可，因为可能只有数值计算的专家才可以理解，好处是 Octave 和 MATLAB  提供了一些库可以直接调用这些算法。</p>
<p>接下来 ng 示范了如何调用这个算法，这一点我们到编程作业的时候继续尝试一下。</p>
<blockquote>
<p>opaque 不透明的</p>
</blockquote>
<h2 id="6-3-Muticlass-Classification"><a href="#6-3-Muticlass-Classification" class="headerlink" title="6.3 Muticlass Classification"></a>6.3 Muticlass Classification</h2><p>这一节讲如何将逻辑回归算法应用到多分类问题上，也即 one-vs-all question。<br>比如一个自动分类邮件到 工作、朋友、家庭、爱好的程序。</p>
<p>one-vs-rest，对于一个分三类的问题，将其分解成3个二分类问题。分别得出三个判别边界。</p>
<p><img src="https://i.loli.net/2020/03/10/Y2oRwWNJMebZA3t.png" alt></p>
<h2 id="Test"><a href="#Test" class="headerlink" title="Test"></a>Test</h2><p><img src="https://i.loli.net/2020/03/10/PgA2F8lrSevT7IX.png" alt><br><strong>Answer:第一项和第四项</strong></p>
<ol>
<li>Suppose you have the following training set, and fit a logistic regression classifier $h_\theta(x) +g(\theta_0+\theta_1x_1+\theta_2x2)$.</li>
</ol>
<p><img src="https://i.loli.net/2020/03/10/QGISbJOPox94hlA.png" alt><br><strong>Answer:第一项和第二项</strong>，这个例子里面线性回归显然是不适合，需要多项式回归，损失函数不可能达到零，一定会有一定大小。而这是一个二分类问题，h(x)必定介于1和0之间。</p>
<p><img src="https://i.loli.net/2020/03/10/dFayDtIo5uhw8SH.png" alt><br><strong>Answer:第一项和第三项</strong>，考察逻辑回归的梯度下降公式里的一些细节，h(x)等于什么很重要。</p>
<p><img src="https://i.loli.net/2020/03/10/Yad7munV34MQCIl.png" alt><br><strong>Answer:第二项和第三项</strong>，对于第一项，这些高级方法的优点在于学习率$\alpha$不用再自己选择，第四项在逻辑回归的开头引出的时候讲了，线性回归的缺陷就在那里。<br><img src="https://i.loli.net/2020/03/10/5EWTpLO1dvbsmfZ.png" alt><br><img src="https://i.loli.net/2020/03/10/FHfw9iVpeSQGLNn.png" alt><br><strong>Answer:第三项</strong>，这个比较好看出来，当x2小于等于6的时候，h(x)是大于0的，对应y=1。</p>

    </div>

    
    
    

      <footer class="post-footer">
          
          <div class="post-tags">
              <a href="/tags/Andrew-Ng-Machine-Learning/" rel="tag"><i class="fa fa-tag"></i> Andrew Ng Machine Learning</a>
              <a href="/tags/MOOC/" rel="tag"><i class="fa fa-tag"></i> MOOC</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-next post-nav-item">
                <a href="/ng_ml/ng_ml_code/" rel="next" title="Machine Learning 编程作业 1 Linear Regression">
                  <i class="fa fa-chevron-left"></i> Machine Learning 编程作业 1 Linear Regression
                </a>
            </div>

            <span class="post-nav-divider"></span>

            <div class="post-nav-prev post-nav-item">
            </div>
          </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          
    <div class="comments" id="comments"></div>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#6-1-Classification-and-Repressentation"><span class="nav-text">6.1 Classification and Repressentation</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#6-1-1-Classification"><span class="nav-text">6.1.1 Classification</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-1-2-Hypothesis-Representation"><span class="nav-text">6.1.2 Hypothesis Representation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-2-1-Decision-Boundary"><span class="nav-text">6.2.1 Decision Boundary</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-2-Logistic-Regression-Model"><span class="nav-text">6.2 Logistic Regression Model</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#6-2-1-Cost-Function"><span class="nav-text">6.2.1 Cost Function</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-2-2-Simplified-Cost-Function-and-Gradient-Descent"><span class="nav-text">6.2.2 Simplified Cost Function and Gradient Descent</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-2-3-Advanced-Optimization"><span class="nav-text">6.2.3 Advanced Optimization</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-3-Muticlass-Classification"><span class="nav-text">6.3 Muticlass Classification</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Test"><span class="nav-text">Test</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <img class="site-author-image" itemprop="image" alt="Li Yao"
    src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">Li Yao</p>
  <div class="site-description" itemprop="description">图书馆里的扫地僧 少林寺里的清洁工</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives">
          <span class="site-state-item-count">56</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">16</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">38</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/GeneralLi95" title="GitHub &rarr; https://github.com/GeneralLi95" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:nudtliyao@foxmail.com" title="E-Mail &rarr; mailto:nudtliyao@foxmail.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://twitter.com/xiaoyaoyao95" title="Twitter &rarr; https://twitter.com/xiaoyaoyao95" rel="noopener" target="_blank"><i class="fa fa-fw fa-twitter"></i>Twitter</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://instagram.com/nudtliyao" title="Instagram &rarr; https://instagram.com/nudtliyao" rel="noopener" target="_blank"><i class="fa fa-fw fa-instagram"></i>Instagram</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://www.zhihu.com/people/li-yao-89-61/activities" title="知乎 &rarr; https://www.zhihu.com/people/li-yao-89-61/activities" rel="noopener" target="_blank"><i class="fa fa-fw fa-zhihu"></i>知乎</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://www.douban.com/people/144704311/" title="豆瓣 &rarr; https://www.douban.com/people/144704311/" rel="noopener" target="_blank"><i class="fa fa-fw fa-douban"></i>豆瓣</a>
      </span>
  </div>
  <div class="cc-license motion-element" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/null" class="cc-opacity" rel="noopener" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a>
  </div>



      </div>
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 2017 – 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Li Yao</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
      <span class="post-meta-item-text">站点总字数：</span>
    <span title="站点总字数">98k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span class="post-meta-item-text">站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">2:43</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">主题 – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

        












        
      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script>
<script src="/js/schemes/pisces.js"></script>
<script src="/js/next-boot.js"></script>



  
















  

  
      
<script type="text/x-mathjax-config">

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });

  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') {
          next = next.nextSibling;
        }
        if (next && next.nodeName.toLowerCase() === 'br') {
          next.parentNode.removeChild(next);
        }
      }
    });
  });

  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      element = document.getElementById(all[i].inputID + '-Frame').parentNode;
      if (element.nodeName.toLowerCase() == 'li') {
        element = element.parentNode;
      }
      element.classList.add('has-jax');
    }
  });
</script>
<script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML', () => {
    MathJax.Hub.Typeset();
  }, window.MathJax);
</script>

    

  


<script>
NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
  var GUEST = ['nick', 'mail', 'link'];
  var guest = 'nick,mail,link';
  guest = guest.split(',').filter(item => {
    return GUEST.includes(item);
  });
  new Valine({
    el: '#comments',
    verify: false,
    notify: false,
    appId: 'UDBji4Ik1sNs3spfpNN5hLtl-gzGzoHsz',
    appKey: 'xXJt7xKWhDQTL58y0eTxw7uA',
    placeholder: "Just go go",
    avatar: 'mm',
    meta: guest,
    pageSize: '10' || 10,
    visitor: true,
    lang: '' || 'zh-cn',
    path: location.pathname,
    recordIP: false,
    serverURLs: ''
  });
}, window.Valine);
</script>

</body>
</html>
