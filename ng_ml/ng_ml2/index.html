<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">
  <meta name="google-site-verification" content="9qoov3_TfJJpNB8lTPmTyQIFty7THrrcKf5gynDis6c">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic|Roboto Mono:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '7.5.0',
    exturl: false,
    sidebar: {"position":"left","display":"always","padding":18,"offset":12,"onmobile":false},
    copycode: {"enable":true,"show_result":true,"style":"mac"},
    back2top: {"enable":true,"sidebar":true,"scrollpercent":true},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: '',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    translation: {
      copy_button: '复制',
      copy_success: '复制成功',
      copy_failure: '复制失败'
    },
    sidebarPadding: 40
  };
</script>

  <meta name="description" content="本节开始以 Linear regression with one variable(一元线性回归)为例，讲述机器学习的基本概念。包括 Model （模型）， Cost Function （损失函数），Parameter Learning （参数学习）等。 2.1 Model Representation hypothesis 假设terminology 术语  以房价预测 Housing Pric">
<meta property="og:type" content="article">
<meta property="og:title" content="Andrew Ng Machine Learning - 2 Linear regression with one variable">
<meta property="og:url" content="http://www.liyaolife.com/ng_ml/ng_ml2/index.html">
<meta property="og:site_name" content="Yao Blog">
<meta property="og:description" content="本节开始以 Linear regression with one variable(一元线性回归)为例，讲述机器学习的基本概念。包括 Model （模型）， Cost Function （损失函数），Parameter Learning （参数学习）等。 2.1 Model Representation hypothesis 假设terminology 术语  以房价预测 Housing Pric">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://i.loli.net/2020/02/21/F7ouwtfCk5Tjiga.png">
<meta property="og:image" content="https://i.loli.net/2020/02/21/xqal1GmMAQsEiX2.png">
<meta property="og:image" content="https://i.loli.net/2020/02/21/VAWfwnGziKTjRxl.png">
<meta property="og:image" content="https://i.loli.net/2020/02/21/AK4CsdXQpN3HG7x.png">
<meta property="og:image" content="https://i.loli.net/2020/02/21/xfBJWAMpEPUONsT.png">
<meta property="og:image" content="https://i.loli.net/2020/02/21/b6Qw5e4kxALZ2Mf.png">
<meta property="og:image" content="https://i.loli.net/2020/02/21/EqnX5URdZVHK4bN.png">
<meta property="og:image" content="https://i.loli.net/2020/02/21/V6fa3DBHTCymUFK.png">
<meta property="og:image" content="https://i.loli.net/2020/02/21/RuQOv6yzEbZaiMD.png">
<meta property="og:image" content="https://i.loli.net/2020/02/21/7kQpWXAIU6GgouN.png">
<meta property="og:image" content="https://i.loli.net/2020/02/21/QOy5aolrA168DP3.png">
<meta property="og:image" content="https://i.loli.net/2020/02/21/mEBtPCvz54Gh1eQ.png">
<meta property="og:image" content="https://i.loli.net/2020/02/21/pRO9rDBC85zqA2W.png">
<meta property="og:image" content="https://i.loli.net/2020/02/21/aIeTfuiDLPkAUM5.png">
<meta property="og:image" content="https://i.loli.net/2020/02/26/eOTamsXcpL5FJdv.png">
<meta property="article:published_time" content="2020-01-10T11:33:51.000Z">
<meta property="article:modified_time" content="2020-02-26T09:28:52.645Z">
<meta property="article:author" content="Li Yao">
<meta property="article:tag" content="Andrew Ng Machine Learning">
<meta property="article:tag" content="MOOC">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://i.loli.net/2020/02/21/F7ouwtfCk5Tjiga.png">

<link rel="canonical" href="http://www.liyaolife.com/ng_ml/ng_ml2/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true,
    isPage: false,
    isArchive: false
  };
</script>

  <title>Andrew Ng Machine Learning - 2 Linear regression with one variable | Yao Blog</title>
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-116714676-1"></script>
    <script>
      var host = window.location.hostname;
      if (host !== "localhost" || !true) {
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'UA-116714676-1');
      }
    </script>


  <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?8f8d97cfe412b0747bae34fbfba6e0f6";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Yao Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">图书馆里的清洁工 少林寺里的扫地僧</p>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类</a>

  </li>
        <li class="menu-item menu-item-读书">

    <a href="https://liyaolife.com/kindle/" rel="noopener" target="_blank"><i class="fa fa-fw fa-book"></i>读书</a>

  </li>
        <li class="menu-item menu-item-友邻">

    <a href="/friend/" rel="section"><i class="fa fa-fw fa-link"></i>友邻</a>

  </li>
  </ul>

</nav>
</div>
    </header>

    

  <a href="https://github.com/GeneralLi95" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://www.liyaolife.com/ng_ml/ng_ml2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Li Yao">
      <meta itemprop="description" content="图书馆里的扫地僧 少林寺里的清洁工">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Yao Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Andrew Ng Machine Learning - 2 Linear regression with one variable
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-01-10 19:33:51" itemprop="dateCreated datePublished" datetime="2020-01-10T19:33:51+08:00">2020-01-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-02-26 17:28:52" itemprop="dateModified" datetime="2020-02-26T17:28:52+08:00">2020-02-26</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning/" itemprop="url" rel="index">
                    <span itemprop="name">Machine Learning</span>
                  </a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning/Stanford-Andrew-Ng-Machine-Learning-Course/" itemprop="url" rel="index">
                    <span itemprop="name">Stanford Andrew Ng Machine Learning Course</span>
                  </a>
                </span>
            </span>

          
            <span id="/ng_ml/ng_ml2/" class="post-meta-item leancloud_visitors" data-flag-title="Andrew Ng Machine Learning - 2 Linear regression with one variable" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/ng_ml/ng_ml2/#comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/ng_ml/ng_ml2/" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="fa fa-file-word-o"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>7.7k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="fa fa-clock-o"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>13 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>本节开始以 Linear regression with one variable(一元线性回归)为例，讲述机器学习的基本概念。包括 Model （模型）， Cost Function （损失函数），Parameter Learning （参数学习）等。</p>
<h2 id="2-1-Model-Representation"><a href="#2-1-Model-Representation" class="headerlink" title="2.1 Model Representation"></a>2.1 Model Representation</h2><blockquote>
<p>hypothesis 假设<br>terminology 术语</p>
</blockquote>
<p>以房价预测 Housing Prices 开始，属于监督学习，Regression<br><img src="https://i.loli.net/2020/02/21/F7ouwtfCk5Tjiga.png" alt=""><br><img src="https://i.loli.net/2020/02/21/xqal1GmMAQsEiX2.png" alt=""><br>这一小节主要就讲了我们如何表示一个模型，输入，输出，函数等一些概念。</p>
<h2 id="2-2-Cost-function"><a href="#2-2-Cost-function" class="headerlink" title="2.2 Cost function"></a>2.2 Cost function</h2><h3 id="2-2-1-Definetion-of-the-cost-function"><a href="#2-2-1-Definetion-of-the-cost-function" class="headerlink" title="2.2.1 Definetion of the cost function"></a>2.2.1 Definetion of the cost function</h3><p>假设：</p>
<script type="math/tex; mode=display">h_{\theta}(x) = \theta_0+\theta_1x</script><p>$\theta_0$ 和 $\theta_1$ 即为这个模型的参数，也即需要学习得出的量。<br>在一元线性回归中，我们希望找出 $\theta_0$ 和 $\theta_1$，使得拟合的曲线非常适合数据。那么问题可以转坏为一个求最小化的问题，即求</p>
<script type="math/tex; mode=display">min_{\theta_0,\theta_1}(h_\theta(x)-y)^2</script><p>取最小值时的 $\theta_0$ 和 $\theta_1$。</p>
<script type="math/tex; mode=display">min_{\theta_0,\theta_1} \frac{1}{2m}\sum^m_{i=1}(h_\theta(x^{(i)})-y^{(i)})^2</script><p>所以我们列出 Cost function ，损失函数</p>
<script type="math/tex; mode=display">J(\theta_0,\theta_1) =  \frac{1}{2m}\sum^m_{i=1}(h_\theta(x^{(i)})-y^{(i)})^2</script><p>我们所求即</p>
<script type="math/tex; mode=display">min_{\theta_0,\theta_1}J(\theta_0,\theta_1)</script><p>这种损失函数也称为 Square error function，平方误差函数。对于大多数Regression问题中，Square error function works well。</p>
<h3 id="2-2-2-Why-we-use-cost-function"><a href="#2-2-2-Why-we-use-cost-function" class="headerlink" title="2.2.2 Why we use cost function"></a>2.2.2 Why we use cost function</h3><p>首先做了一个假设，假设$\theta<em>0=0$,来简化问题。<br><img src="https://i.loli.net/2020/02/21/VAWfwnGziKTjRxl.png" alt=""><br>$h</em>\theta(x)$是对于固定的 $\theta$ ，是一个$x$的函数，$J(\theta_1)$是一个关于$\theta$的函数。<br><strong>quiz:</strong><br><img src="https://i.loli.net/2020/02/21/AK4CsdXQpN3HG7x.png" alt=""><br>注意 $J(\theta_1)$ 是关于 $\theta$的函数，所以$J(0)$，对应的$h(x)$，就是x轴，所以结果是 $(1+2^2+3^2)/6=14/6$<br><img src="https://i.loli.net/2020/02/21/xfBJWAMpEPUONsT.png" alt=""><br>这张图表示了$J(\theta_1)$变化曲线，可见$\theta_1=1$的时候$J(\theta_1)=0$，完美拟合。</p>
<h3 id="2-2-3-Deeper-and-better-intuition-about-cost-function"><a href="#2-2-3-Deeper-and-better-intuition-about-cost-function" class="headerlink" title="2.2.3 Deeper and better intuition about cost function"></a>2.2.3 Deeper and better intuition about cost function</h3><blockquote>
<p>intuition 直觉<br>contour plot 等高线</p>
</blockquote>
<p>上一小节讨论了简化的损失函数，即在$\theta_0=0$的情况下，这一节开始讨论包含 $\theta_0$的情况下的损失函数。当只有一个参数($\theta_1$)的时候，损失函数$J(\theta)$的曲线是一个二次函数。而当有两个参数的时候，损失函数的表式编程了一个三维曲面。而将三维曲面二维化的方式就是等高线<code>contour plot</code>。在具有更多参数的时候，损失函数将会是高维曲面，无法直观看出来。<br><img src="https://i.loli.net/2020/02/21/b6Qw5e4kxALZ2Mf.png" alt=""><br><img src="https://i.loli.net/2020/02/21/EqnX5URdZVHK4bN.png" alt=""></p>
<h2 id="2-3-Parameter-Learning"><a href="#2-3-Parameter-Learning" class="headerlink" title="2.3 Parameter Learning"></a>2.3 Parameter Learning</h2><h3 id="2-3-1-Gradient-Descent"><a href="#2-3-1-Gradient-Descent" class="headerlink" title="2.3.1 Gradient Descent"></a>2.3.1 Gradient Descent</h3><blockquote>
<p>optimum 最佳<br>dirivative 偏导</p>
</blockquote>
<p>损失函数如何求取最佳的 $\theta$组合，通过图像绘制是一种方法，但是高维损失函数无法直接绘出。所以需要有自动化的方法。本节介绍一种方法，Gradient Descent 梯度下降法。这是在深度学习中广泛使用的函数最优化方法，并非只用在线性回归的损失函数上。<br>在已知$J(\theta_0,\theta_1)$，也可能是$J(\theta_0,\theta_1,…,\theta_n)$，的情况下求$minJ(\theta_0,\theta_1)$</p>
<p>Outline：</p>
<ul>
<li>Start with some $\theta_0, \theta_1$</li>
<li>Keep changing $\theta_0,\theta_1$ to reduce $J(\theta_0,\theta_1)$ until we hopefully end up at a minimum</li>
</ul>
<p>在三维曲面上，损失函数的曲线，像地形，寻找最小值的过程像一个下山的过程，梯度下降法就是寻找最快下山路径的算法。这里存在一些问题，地形可能存在，「鞍点」local optimum，即局部最佳值，选取不同的初始值，可能会走入不同的局部最佳值。</p>
<p><img src="https://i.loli.net/2020/02/21/V6fa3DBHTCymUFK.png" alt=""></p>
<blockquote>
<p>Gradient descent algorithm<br>repeat until convergence<br>$\theta_j := \theta_j - \alpha \frac{\partial}{\partial \theta_0} J(\theta_0,\theta_1)$ （for $j=0$ and $j=1$)</p>
</blockquote>
<p>$\alpha $在此处即为 learning rate，学习率，后面会讲到。<br><img src="https://i.loli.net/2020/02/21/RuQOv6yzEbZaiMD.png" alt=""></p>
<p>注意，要两个值都计算完了再更新，而不是计算一个更新一个。</p>
<blockquote>
<p>:= 是在 Pascal 语言当中作为 赋值语句用的<br>simultaneous 同时的，并发的</p>
</blockquote>
<p><strong>quiz</strong><br><img src="https://i.loli.net/2020/02/21/7kQpWXAIU6GgouN.png" alt=""></p>
<p>刚开始还以为这道题涉及求导，后来发现这道题根本不需要求导，直接带入就出来了。选第二项。</p>
<h3 id="2-3-2-Gradient-Descent-Intuition"><a href="#2-3-2-Gradient-Descent-Intuition" class="headerlink" title="2.3.2 Gradient Descent Intuition"></a>2.3.2 Gradient Descent Intuition</h3><blockquote>
<p>Intuition 直觉</p>
</blockquote>
<p>前一部分讲了梯度下降法的定义，这一部分进一步讲了其原理。<br><img src="https://i.loli.net/2020/02/21/QOy5aolrA168DP3.png" alt=""></p>
<p>一步步拆解了梯度下降法的一个原理，在曲线右侧，斜率为正，更新后$\theta_1$减小，向左移动，在曲线左侧，斜率为负，更新后负负得正,$\theta_1$增加，向右移动。而每次移动多少，除了受斜率影响，还会受系数 $\alpha$ 影响，做个 $\alpha$，即成为学习率。显然，如果学习率太小，则每次移动速度会非常小，收敛速度很慢，如果学习率很大，则收敛速度会过快，甚至<code>over shoot</code></p>
<p><strong>quiz</strong><br><img src="https://i.loli.net/2020/02/21/mEBtPCvz54Gh1eQ.png" alt=""></p>
<ul>
<li><strong>Leave $\theta_1$ unchanged</strong></li>
<li>Change $\theta_1$ in a random direction</li>
<li>Move $\theta_1$ in the direction of the global minimum of $J(\theta_1)$</li>
<li>Derease $\theta_1$<br>按照公式此处$\theta_1$<br>按照公式此处$\theta_1$偏导数是0，所以不会变。这也显示了它可能会陷入局部最优解。</li>
</ul>
<p>先暂时不考虑局部最优解问题，由于每次更新后，偏导数（即斜率）是越来越小的，所以梯度下降法的 steps，会随之变小，即使学习率$\alpha$是固定的。</p>
<h3 id="2-3-2-Gradient-For-Linear-regression"><a href="#2-3-2-Gradient-For-Linear-regression" class="headerlink" title="2.3.2 Gradient For Linear regression"></a>2.3.2 Gradient For Linear regression</h3><blockquote>
<p>convex funciton 凸函数，关于凸函数，高中数学的定义讲的十分混乱，有非常多的版本，这里我们采用和课程一致的，也是维基百科的版本，即二阶导数大于零，bowl shape function 碗型函数</p>
</blockquote>
<p>前一部分都是定性的讲解梯度下降法的原理，这一部分开始带入一元线性回归的损失函数，来实际使用一下梯度下降法。<br><img src="https://i.loli.net/2020/02/21/pRO9rDBC85zqA2W.png" alt=""><br>前文已经提到，一元线性回归的损失函数为</p>
<script type="math/tex; mode=display">J(\theta_0,\theta_1) =  \frac{1}{2m}\sum^m_{i=1}(h_\theta(x^{(i)})-y^{(i)})^2</script><p>将$h_{\theta}(x) = \theta_0 + \theta_1 x$ 代入，可得</p>
<script type="math/tex; mode=display">J(\theta_0,\theta_1) =  \frac{1}{2m}\sum^m_{i=1}(\theta_0 + \theta_1 x^{(i)}-y^{(i)})^2</script><p>分别对 $\theta_0$ 和 $\theta_1$求偏导可得</p>
<script type="math/tex; mode=display">\frac{\partial}{\partial_{\theta_0}}J(\theta_0,\theta_1) =  \frac{1}{m}\sum^m_{i=1}(\theta_0 + \theta_1 x^{(i)}-y^{(i)})</script><script type="math/tex; mode=display">\frac{\partial}{\partial_{\theta_1}}J(\theta_0,\theta_1) =  \frac{1}{m}\sum^m_{i=1}(\theta_0 + \theta_1 x^{(i)}-y^{(i)})x^{(i)}</script><p>即如下图所示的推导<br><img src="https://i.loli.net/2020/02/21/aIeTfuiDLPkAUM5.png" alt=""><br>继而，迭代公式即</p>
<script type="math/tex; mode=display">\theta_0 :=\theta_0 - \alpha \frac{1}{m}\sum^m_{i=1}(\theta_0 + \theta_1 x^{(i)}-y^{(i)})</script><script type="math/tex; mode=display">\theta_1 := \theta_1 - \alpha \frac{1}{m}\sum^m_{i=1}(\theta_0 + \theta_1 x^{(i)}-y^{(i)})x^{(i)}</script><p>暂时不考虑局部最优解问题，因为线性回归问题的损失函数都是<code>convex functinon</code>凸函数，也即碗型函数。这些函数没有 <code>local optimum</code>，只有一个 <code>global optimum</code>。</p>
<p>‘Batch’ 批处理，梯度下降的每次迭代都要用到所有训练数据，因为计算损失函数的时候需要代入所有的 x,y 值。在线性回归问题中，batch 是所有数据，在其他一些机器学习问题中，batch 有时候是整个训练集的子集。</p>
<p><strong>quiz:</strong></p>
<p>Which of the following are true statements? Select all that apply.</p>
<ul>
<li>To make gradient descent converge, we must slowly decrease $\alpha$ over time.</li>
<li>Gradient descent is guaranteed to find the global minimum for any function $J(\theta_0,\theta_1)$</li>
<li><strong>Gradient descent can converge even if $\alpha$ is kept fixed. (But $\alpha$ cannot be too large, or else it may fail to converge.)</strong></li>
<li><strong>For the specific choice of cost function $J(\theta_0,\theta_1)$ used in linear regression, there are no local optima (other than the global optimum).</strong></li>
</ul>
<p>这道题让选正确表述，前面都已经写得比较细了，一个是即使学习率固定，梯度下降法的步长依然会依次减小。另外一个是对于现行回归问题，没有局部最优，只有全局最优，所以不需要考虑「鞍点」的问题。</p>
<h2 id="2-4-Test"><a href="#2-4-Test" class="headerlink" title="2.4 Test"></a>2.4 Test</h2><p>1.Consider the problem of predicting how well a student does in her second year of college/university, given how well she did in her first year.<br>Specifically, let x be equal to the number of “A” grades (including A-. A and A+ grades) that a student receives in their first year of college (freshmen year). We would like to predict the value of y, which we define as the number of “A” grades they get in their second year (sophomore year).<br>Refer to the following training set of a small sample of different students’ performances (note that this training set may also be referenced in other questions in this quiz). Here each row is one training example. Recall that in linear regression, our hypothesis is $h_\theta(x) = \theta_0 + \theta_1x$, and we use mm to denote the number of training examples.</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>x</th>
<th>y</th>
</tr>
</thead>
<tbody>
<tr>
<td>3</td>
<td>4</td>
</tr>
<tr>
<td>2</td>
<td>1</td>
</tr>
<tr>
<td>4</td>
<td>3</td>
</tr>
<tr>
<td>0</td>
<td>1</td>
</tr>
</tbody>
</table>
</div>
<p>For the training set given above, what is the value of mm? In the box below, please enter your answer (which should be a number between 0 and 10).<br><strong>Answer:4</strong><br>这一题求 m，其实就是找有几个样本，不需要计算直接得到4.<br>2.Consider the following training set of $m = 4$ training examples:</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>x</th>
<th>y</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>0.5</td>
</tr>
<tr>
<td>2</td>
<td>1</td>
</tr>
<tr>
<td>4</td>
<td>2</td>
</tr>
<tr>
<td>0</td>
<td>0</td>
</tr>
</tbody>
</table>
</div>
<p>Consider the linear regression model $h_\theta(x) = \theta_0 + \theta_1x$. What are the values of $\theta_0$ and $\theta_1$ that you would expect to obtain upon running gradient descent on this model? (Linear regression will be able to fit this data perfectly.)</p>
<ul>
<li><strong>$\theta_0 = 0, \theta_1 = 0.5$</strong></li>
<li>$\theta_0 = 1, \theta_1 = 0.5$</li>
<li>$\theta_0 = 0.5, \theta_1 = 0.5$</li>
<li>$\theta_0 = 1, \theta_1 = 1$</li>
<li>$\theta_0 = 0.5, \theta_1 = 0.5$</li>
</ul>
<p>这道题在坐标图上一画就很直观。<br>3.Suppose we set $\theta<em>0 = -1, \theta_1 = 2$ in the linear regression hypothesis from Q1. What is $h</em>{\theta}(6)$?<br>    <strong>Answer: 11</strong><br>$2 \times 6-1 =11$</p>
<p>4.In the given figure, the cost function $J(\theta_0,\theta_1)$ has been plotted against $\theta_0$ and $theta_1$, as shown in ‘Plot 2’. The contour plot for the same cost function is given in ‘Plot 1’. Based on the figure, choose the correct options (check all that apply).<br><img src="https://i.loli.net/2020/02/26/eOTamsXcpL5FJdv.png" alt=""></p>
<ul>
<li>Point P (The global minimum of plot 2) corresponds to point C of Plot 1.</li>
<li><strong>If we start from point B, gradient descent with a well-chosen learning rate will eventually help us reach at or near point A, as the value of cost function $J(\theta_0,\theta_1)$ is minimum at A.</strong></li>
<li>If we start from point B, gradient descent with a well-chosen learning rate will eventually help us reach at or near point A, as the value of cost function $J(\theta_0,\theta_1)$ is maximum at point A.</li>
<li><strong>Point P (the global minimum of plot 2) corresponds to point A of Plot 1.</strong></li>
<li>If we start from point B, gradient descent with a well-chosen learning rate will eventually help us reach at or near point C, as the value of cost function $J(\theta_0,\theta_1)$ is minimum at point C.</li>
</ul>
<p>这道题考察对于损失函数的理解。</p>
<p>5.Suppose that for some linear regression problem (say, predicting housing prices as in the lecture), we have some training set, and for our training set we managed to find some $\theta_0$, $\theta_1$ such that $J(\theta_0, \theta_1)=0$.<br>Which of the statements below must then be true? (Check all that apply.)</p>
<ul>
<li>For this to be true, we must have $\theta<em>0 = 0$ and $\theta_1 = 0$ so that $h</em>\theta(x) = 0$</li>
<li>This is not possible: By the definition of $J(\theta_0, \theta_1)$, it is not possible for there to exist $\theta_0$ and $\theta_1$ so that $J(\theta_0, \theta_1) = 0$</li>
<li><strong>For these values of $\theta<em>0$ and $\theta_1$ that satisfy $J(\theta_0, \theta_1) = 0$, we have that $h</em>\theta(x^{(i)}) = y^{(i)}$ for every training example $(x^{(i)}, y^{(i)})$</strong></li>
<li>We can perfectly predict the value of yy even for new examples that we have not yet seen.(e.g., we can perfectly predict prices of even new houses that we have not yet seen.)</li>
<li>Gradient descent is likely to get stuck at a local minimum and fail to find the global minimum.</li>
<li>For this to be true, we must have $y^{(i)} = 0$ for every value of $i = 1, 2, \ldots, m$.</li>
<li>For this to be true, we must have $\theta<em>0 = 0$ and $\theta_1 = 0$ so that $h</em>\theta(x) = 0$</li>
<li><strong>Our training set can be fit perfectly by a straight line, i.e., all of our training examples lie perfectly on some straight line.</strong></li>
</ul>
<p>这道题损失函数是零，说明，所有点都与拟合线重合，对于一元回归问题，一定是直线。</p>

    </div>

    
    
    

      <footer class="post-footer">
          
          <div class="post-tags">
              <a href="/tags/Andrew-Ng-Machine-Learning/" rel="tag"><i class="fa fa-tag"></i> Andrew Ng Machine Learning</a>
              <a href="/tags/MOOC/" rel="tag"><i class="fa fa-tag"></i> MOOC</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-next post-nav-item">
                <a href="/tianchi_ocean/" rel="next" title="2020天池智慧海洋建设比赛">
                  <i class="fa fa-chevron-left"></i> 2020天池智慧海洋建设比赛
                </a>
            </div>

            <span class="post-nav-divider"></span>

            <div class="post-nav-prev post-nav-item">
                <a href="/mkdocs/" rel="prev" title="mkdocs 使用">
                  mkdocs 使用 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          
    <div class="comments" id="comments"></div>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#2-1-Model-Representation"><span class="nav-text">2.1 Model Representation</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-2-Cost-function"><span class="nav-text">2.2 Cost function</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-1-Definetion-of-the-cost-function"><span class="nav-text">2.2.1 Definetion of the cost function</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-2-Why-we-use-cost-function"><span class="nav-text">2.2.2 Why we use cost function</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-3-Deeper-and-better-intuition-about-cost-function"><span class="nav-text">2.2.3 Deeper and better intuition about cost function</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-3-Parameter-Learning"><span class="nav-text">2.3 Parameter Learning</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-3-1-Gradient-Descent"><span class="nav-text">2.3.1 Gradient Descent</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-3-2-Gradient-Descent-Intuition"><span class="nav-text">2.3.2 Gradient Descent Intuition</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-3-2-Gradient-For-Linear-regression"><span class="nav-text">2.3.2 Gradient For Linear regression</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-4-Test"><span class="nav-text">2.4 Test</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <img class="site-author-image" itemprop="image" alt="Li Yao"
    src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">Li Yao</p>
  <div class="site-description" itemprop="description">图书馆里的扫地僧 少林寺里的清洁工</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives">
          <span class="site-state-item-count">60</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">17</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">39</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/GeneralLi95" title="GitHub &rarr; https://github.com/GeneralLi95" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:nudtliyao@foxmail.com" title="E-Mail &rarr; mailto:nudtliyao@foxmail.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://twitter.com/xiaoyaoyao95" title="Twitter &rarr; https://twitter.com/xiaoyaoyao95" rel="noopener" target="_blank"><i class="fa fa-fw fa-twitter"></i>Twitter</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://instagram.com/nudtliyao" title="Instagram &rarr; https://instagram.com/nudtliyao" rel="noopener" target="_blank"><i class="fa fa-fw fa-instagram"></i>Instagram</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://www.zhihu.com/people/li-yao-89-61/activities" title="知乎 &rarr; https://www.zhihu.com/people/li-yao-89-61/activities" rel="noopener" target="_blank"><i class="fa fa-fw fa-zhihu"></i>知乎</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://www.douban.com/people/144704311/" title="豆瓣 &rarr; https://www.douban.com/people/144704311/" rel="noopener" target="_blank"><i class="fa fa-fw fa-douban"></i>豆瓣</a>
      </span>
  </div>
  <div class="cc-license motion-element" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/null" class="cc-opacity" rel="noopener" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a>
  </div>



      </div>
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 2017 – 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Li Yao</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
      <span class="post-meta-item-text">站点总字数：</span>
    <span title="站点总字数">105k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span class="post-meta-item-text">站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">2:55</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">主题 – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

        












        
      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  
















  

  
      
<script type="text/x-mathjax-config">

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });

  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') {
          next = next.nextSibling;
        }
        if (next && next.nodeName.toLowerCase() === 'br') {
          next.parentNode.removeChild(next);
        }
      }
    });
  });

  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      element = document.getElementById(all[i].inputID + '-Frame').parentNode;
      if (element.nodeName.toLowerCase() == 'li') {
        element = element.parentNode;
      }
      element.classList.add('has-jax');
    }
  });
</script>
<script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML', () => {
    MathJax.Hub.Typeset();
  }, window.MathJax);
</script>

    

  


<script>
NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
  var GUEST = ['nick', 'mail', 'link'];
  var guest = 'nick,mail,link';
  guest = guest.split(',').filter(item => {
    return GUEST.includes(item);
  });
  new Valine({
    el: '#comments',
    verify: false,
    notify: false,
    appId: 'UDBji4Ik1sNs3spfpNN5hLtl-gzGzoHsz',
    appKey: 'xXJt7xKWhDQTL58y0eTxw7uA',
    placeholder: "Just go go",
    avatar: 'mm',
    meta: guest,
    pageSize: '10' || 10,
    visitor: true,
    lang: '' || 'zh-cn',
    path: location.pathname,
    recordIP: false,
    serverURLs: ''
  });
}, window.Valine);
</script>

</body>
</html>
